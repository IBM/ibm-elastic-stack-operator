#
# Copyright 2020 IBM Corporation
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

general:
  environment: IBMCloudPrivate
  clusterDomain: cluster.local
  clusterName: mycluster
  ingressPort: 8443

image:
  pullPolicy: IfNotPresent
  pullSecret:
    enabled: false
    name: regcred

security:
  ca:
    keystore:
      password: changeme
    truststore:
      password: changeme
    # set to `external` to use existing CA stored in Kubernetes secret to generate certs
    origin: internal
    external:
      # the secret need to be in the same namespace as the chart release
      secretName: cluster-ca-cert
      # the Kubenetes field name (key) within the specified secret that stores CA cert
      certFieldName: tls.crt
      # the Kubenets field name (key) within the specified secret that stores CA private key
      keyFieldName: tls.key
  app:
    keystore:
      password: changeme
  tls:
    version: TLSv1.2

logstash:
  replicas: 1
  name: logstash
  heapSize: "512m"
  memoryLimit: "1024Mi"
  port: 5000
  image:
    repository: "quay.io/opencloudio/icp-logstash-oss"
    tag: "6.8.10-build.3"
    digest: "sha256:9d2630efe8e492fc97821f79d5871b7d53c4420fc4dd2c0e449d3f767e4ba3e0"
  nodeSelector:
  tolerations: []
kibana:
  install: true
  replicas: 1
  name: kibana
  nodeSelector:
  tolerations: []
  # accepted values:
  # ingress or loadBalancer, defaults to loadBalancer
  access: loadBalancer
  ingress:
    # "/kibana" for managed service logging instance
    # sample value for custom ingress: "/tenantA/kibana"
    # no trailing /
    path: "/tenantA/kibana"
    # additional labels to facilitate link rendering in icp console
    labels:
      inmenu: "true"
      # if provided, the link will open in a new tab with the target value in the <a> tag
      target: "logging-sampleA"
    annotations:
  service:
    # additional labels to facilitate link rendering in icp console
    labels:
      inmenu: "true"
      # if provided, the link will open in a new tab with the target value in the <a> tag
      target: "logging-sampleA"
    # additional annotations to facilitate link rendering in icp console
    annotations:
      # display name that will show in the menu
      name: "Logging - Sample A"
      # provided by icp console
      id: "add-ons"
      # list of roles to be able to view TA in the menu
      roles: "ClusterAdministrator,Administrator,Operator,Viewer"
      # show link if user is in any of the teams
      # ui.icp.ibm.com/tenant:
  internal: 5601
  # port to access the kibana instance from outside the cluster
  # only used when ingress set to loadBalancer
  external: 31601
  # maximum old space size (in MB) of the V8 Javascript engine
  maxOldSpaceSize: "1536"
  memoryLimit: "2048Mi"
  image:
    repository: quay.io/opencloudio/icp-kibana-oss
    tag: 6.8.10-build.3
    digest: "sha256:fceed38cd068aac38437ee4ed1159c3b7130eacb7fb43247602e706c8bf26ccb"
  init:
    resources:
      limits:
        memory: 256Mi
      requests:
        memory: 64Mi
  initImage:
    repository: "quay.io/opencloudio/curl"
    tag: "4.2.0-build.8"
    digest: "sha256:1f8d46187c2330a73c895f37aa010235288083972516f97fe518247c8a68dc57"
  routerImage:
    repository: "quay.io/opencloudio/icp-management-ingress"
    tag: "2.5.9"
    digest: "sha256:fedfb66a2c552d6bf1a741dbe42b74aaf0775f8a0618b1f39815474ebc811b7b"
    resources:
      limits:
        memory: 256Mi
      requests:
        memory: 64Mi
  security:
    authc:
      enabled: false
      # accepted values: icp
      # what it does: redirects to icp login page first
      provider: icp
    authz:
      enabled: false
      # accepted values: icp
      # what it does: only allow request to pass if user
      # have access to the required namespaces
      # that the current user has access to
      # requires authc.enabled = true and authc.provider = icp
      provider: icp
      icp:
        # 1. user is allowed to access the kibana ingress
        #    if namespaces granted to user are listed below
        # 2. when the list below is empty, only cluster admin
        #    can access this kibana ingress
        authorizedNamespaces:
          - tenantadev
          - tenantatest
          - tenantaprod

filebeat:
  name: filebeat-ds
  resources:
    limits:
      memory: 256Mi
    requests:
      memory: 64Mi
  image:
    repository: "quay.io/opencloudio/icp-filebeat-oss"
    tag: "6.8.10-build.3"
    digest: "sha256:42ef999c708e91f658e71d2983f9c675bf815b9dc0a838fe34de8f6c4d432acf"
  scope:
    nodes: {}
    namespaces: []
  tolerations: []
  registryHostPath: "/var/lib/icp/logging/filebeat-registry/{{ .Release.Name }}"
  # accepted values: text, json
  # what it does: parses the log data as json or text
  logFormat: text
elasticsearch:
  name: "elasticsearch"
  internalPort: 9300
  image:
    repository: "quay.io/opencloudio/icp-elasticsearch-oss"
    tag: "6.8.10-build.3"
    digest: "sha256:6ece80649d7be909986776b8b5a85c620e855626c7deb262ffd91b07f2c69e5f"
  pkiInitImage:
    repository: "quay.io/opencloudio/logging-pki-init"    
    tag: "2.3.0-build.6"
    digest: "sha256:dec6554c855f7fe1b00b9e4dffd1482828b3bfd4a40198bafed2e2dfc582b06d"
    resources:
      limits:
        memory: 512Mi
      requests:
        memory: 64Mi
  initImage:
    repository: "quay.io/opencloudio/icp-initcontainer"
    tag: "1.0.0-build.8"
    digest: "sha256:c0820a378fe87f79e0d553e3ff0bc4dc3d2d3312b7b6ae0c788f9bfe8a632966"
  routerImage:
    repository: "quay.io/opencloudio/icp-management-ingress"
    tag: "2.5.9"
    digest: "sha256:fedfb66a2c552d6bf1a741dbe42b74aaf0775f8a0618b1f39815474ebc811b7b"
    resources:
       limits:
         memory: 256Mi
       requests:
         memory: 64Mi
  security:
    authc:
      # accepted values: true
      enabled: true
      # accepted values: nginx
      # what it does: mtls authz with account rbac
      provider: nginx
    authz:
      enabled: false
      # accepted values: icp
      # what it does: filter log content by the namespace
      # that the current user has access to
      provider: icp

  client:
    restPort: 9200

  data:
    name: data
    # Set to the # of management (or master, if no mgmt) nodes
    replicas: 2
    heapSize: 4000m
    memoryLimit: 7000M
    antiAffinity: hard
    tolerations: []
    nodeSelector:
    storage:
      # When true will expect a PersistentVolume
      persistent: true
      # Set to true if you are using GlusterFS or other dynamic provisioner
      useDynamicProvisioning: false
      # If not using dynamic provisioning, you can use selectors to refine the binding process.
      # These are IGNORED if using dynamic provisioning.
      selector:
        label: ""
        value: ""
      # 30Gi is not the recommended size, but rather a small default.
      # It will match much larger drives as well.
      size: 30Gi
      accessModes:
        - ReadWriteOnce
      ## Specify the storageClass name you want to use
      ## If you don't specify a storageClass name it will use the default
      storageClass: ""

curator:
  name: log-curator
  resources:
    limits:
      memory: 256Mi
    requests:
      memory: 64Mi
  image:
    repository: "quay.io/opencloudio/indices-cleaner"
    tag: "1.3.0-build.3"
    digest: "sha256:1bf890d6a970406df756f0c4bd7f6d906617d36ad5b43a66cdddbf8de4384cdb"
  # runs at 23:30 UTC daily
  schedule: "30 23 * * *"
  nodeSelector:
  tolerations: []
  app:
    unit: days
    count: 1
  monitoring:
    unit: days
    count: 7
  watcher:
    unit: days
    count: 1
  va:
    unit: days
    count: 90
  mapp:
    unit: days
    count: 2
  auditLog:
    unit: days
    count: 1

upgrade:
  elasticsearch:
    # set to true if data from old version need to be imported
    importData: true
    # if set to true, a copy of existing data in old format will be left intact
    # under pv-mount/nodes (/usr/share/elasticsearch/data/nodes)
    # this allows data (up to point of upgrade) to be restored when rolling back
    retainOldData: true
